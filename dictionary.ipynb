{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "790542f8-21b2-4a41-afee-82ce18674885",
      "metadata": {
        "id": "790542f8-21b2-4a41-afee-82ce18674885"
      },
      "source": [
        "# MR Fingerprinting Dictionary Generation\n",
        "\n",
        "In this example we demonstrate how to generate an MR Fingerprinting dictionary using a FISP type sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But first we have to install Julia (v1.10.6) on the current Colab Runtime."
      ],
      "metadata": {
        "id": "DCgjuTdcIqwX"
      },
      "id": "DCgjuTdcIqwX"
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "set -e\n",
        "\n",
        "#---------------------------------------------------#\n",
        "JULIA_VERSION=\"1.10.6\"\n",
        "JULIA_PACKAGES=\"IJulia\"\n",
        "JULIA_PACKAGES_IF_GPU=\"CUDA\" # or CuArrays for older Julia versions\n",
        "JULIA_NUM_THREADS=4\n",
        "#---------------------------------------------------#\n",
        "\n",
        "if [ -z `which julia` ]; then\n",
        "  # Install Julia\n",
        "  JULIA_VER=`cut -d '.' -f -2 <<< \"$JULIA_VERSION\"`\n",
        "  echo \"Installing Julia $JULIA_VERSION on the current Colab Runtime...\"\n",
        "  BASE_URL=\"https://julialang-s3.julialang.org/bin/linux/x64\"\n",
        "  URL=\"$BASE_URL/$JULIA_VER/julia-$JULIA_VERSION-linux-x86_64.tar.gz\"\n",
        "  wget -nv $URL -O /tmp/julia.tar.gz # -nv means \"not verbose\"\n",
        "  tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
        "  rm /tmp/julia.tar.gz\n",
        "\n",
        "  # Install Packages\n",
        "  nvidia-smi -L &> /dev/null && export GPU=1 || export GPU=0\n",
        "  if [ $GPU -eq 1 ]; then\n",
        "    JULIA_PACKAGES=\"$JULIA_PACKAGES $JULIA_PACKAGES_IF_GPU\"\n",
        "  fi\n",
        "  for PKG in `echo $JULIA_PACKAGES`; do\n",
        "    echo \"Installing Julia package $PKG...\"\n",
        "    julia -e 'using Pkg; pkg\"add '$PKG'; precompile;\"' &> /dev/null\n",
        "  done\n",
        "\n",
        "  # Install kernel and rename it to \"julia\"\n",
        "  echo \"Installing IJulia kernel...\"\n",
        "  julia -e 'using IJulia; IJulia.installkernel(\"julia\", env=Dict(\n",
        "      \"JULIA_NUM_THREADS\"=>\"'\"$JULIA_NUM_THREADS\"'\"))'\n",
        "  KERNEL_DIR=`julia -e \"using IJulia; print(IJulia.kerneldir())\"`\n",
        "  KERNEL_NAME=`ls -d \"$KERNEL_DIR\"/julia*`\n",
        "  mv -f $KERNEL_NAME \"$KERNEL_DIR\"/julia\n",
        "\n",
        "  echo ''\n",
        "  echo \"Successfully installed `julia -v`!\"\n",
        "  echo \"Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\"\n",
        "  echo \"jump to the 'Checking the Installation' section.\"\n",
        "fi"
      ],
      "metadata": {
        "id": "uxNYwOH4INrZ",
        "outputId": "ecf5b7f2-b421-44e7-a319-762a090c6fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "uxNYwOH4INrZ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Julia 1.10.6 on the current Colab Runtime...\n",
            "2024-11-24 12:25:23 URL:https://storage.googleapis.com/julialang2/bin/linux/x64/1.10/julia-1.10.6-linux-x86_64.tar.gz [174129316/174129316] -> \"/tmp/julia.tar.gz\" [1]\n",
            "Installing Julia package IJulia...\n",
            "Installing IJulia kernel...\n",
            "/bin/bash: line 32: LD_PRELOAD_: command not found\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'set -e\n\n#---------------------------------------------------#\nJULIA_VERSION=\"1.10.6\"\nJULIA_PACKAGES=\"IJulia\"\nJULIA_PACKAGES_IF_GPU=\"CUDA\" # or CuArrays for older Julia versions\nJULIA_NUM_THREADS=4\n#---------------------------------------------------#\n\nif [ -z `which julia` ]; then\n  # Install Julia\n  JULIA_VER=`cut -d '.' -f -2 <<< \"$JULIA_VERSION\"`\n  echo \"Installing Julia $JULIA_VERSION on the current Colab Runtime...\"\n  BASE_URL=\"https://julialang-s3.julialang.org/bin/linux/x64\"\n  URL=\"$BASE_URL/$JULIA_VER/julia-$JULIA_VERSION-linux-x86_64.tar.gz\"\n  wget -nv $URL -O /tmp/julia.tar.gz # -nv means \"not verbose\"\n  tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n  rm /tmp/julia.tar.gz\n\n  # Install Packages\n  nvidia-smi -L &> /dev/null && export GPU=1 || export GPU=0\n  if [ $GPU -eq 1 ]; then\n    JULIA_PACKAGES=\"$JULIA_PACKAGES $JULIA_PACKAGES_IF_GPU\"\n  fi\n  for PKG in `echo $JULIA_PACKAGES`; do\n    echo \"Installing Julia package $PKG...\"\n    julia -e 'using Pkg; pkg\"add '$PKG'; precompile;\"' &> /dev/null\n  done\n\n  # Install kernel and rename it to \"julia\"\n  echo \"Installing IJulia kernel...\"\n  LD_PRELOAD_ julia -e 'using IJulia; IJulia.installkernel(\"julia\", env=Dict(\n      \"JULIA_NUM_THREADS\"=>\"'\"$JULIA_NUM_THREADS\"'\"))'\n  KERNEL_DIR=`julia -e \"using IJulia; print(IJulia.kerneldir())\"`\n  KERNEL_NAME=`ls -d \"$KERNEL_DIR\"/julia*`\n  mv -f $KERNEL_NAME \"$KERNEL_DIR\"/julia  \n\n  echo ''\n  echo \"Successfully installed `julia -v`!\"\n  echo \"Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\"\n  echo \"jump to the 'Checking the Installation' section.\"\nfi\n' returned non-zero exit status 127.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0ecdd3488584>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'set -e\\n\\n#---------------------------------------------------#\\nJULIA_VERSION=\"1.10.6\"\\nJULIA_PACKAGES=\"IJulia\"\\nJULIA_PACKAGES_IF_GPU=\"CUDA\" # or CuArrays for older Julia versions\\nJULIA_NUM_THREADS=4\\n#---------------------------------------------------#\\n\\nif [ -z `which julia` ]; then\\n  # Install Julia\\n  JULIA_VER=`cut -d \\'.\\' -f -2 <<< \"$JULIA_VERSION\"`\\n  echo \"Installing Julia $JULIA_VERSION on the current Colab Runtime...\"\\n  BASE_URL=\"https://julialang-s3.julialang.org/bin/linux/x64\"\\n  URL=\"$BASE_URL/$JULIA_VER/julia-$JULIA_VERSION-linux-x86_64.tar.gz\"\\n  wget -nv $URL -O /tmp/julia.tar.gz # -nv means \"not verbose\"\\n  tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\\n  rm /tmp/julia.tar.gz\\n\\n  # Install Packages\\n  nvidia-smi -L &> /dev/null && export GPU=1 || export GPU=0\\n  if [ $GPU -eq 1 ]; then\\n    JULIA_PACKAGES=\"$JULIA_PACKAGES $JULIA_PACKAGES_IF_GPU\"\\n  fi\\n  for PKG in `echo $JULIA_PACKAGES`; do\\n    echo \"Installing Julia package $PKG...\"\\n    julia -e \\'using Pkg; pkg\"add \\'$PKG\\'; precompile;\"\\' &> /dev/null\\n  done\\n\\n  # Install kernel and rename it to \"julia\"\\n  echo \"Installing IJulia kernel...\"\\n  LD_PRELOAD_ julia -e \\'using IJulia; IJulia.installkernel(\"julia\", env=Dict(\\n      \"JULIA_NUM_THREADS\"=>\"\\'\"$JULIA_NUM_THREADS\"\\'\"))\\'\\n  KERNEL_DIR=`julia -e...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0mreturncode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       )\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'set -e\n\n#---------------------------------------------------#\nJULIA_VERSION=\"1.10.6\"\nJULIA_PACKAGES=\"IJulia\"\nJULIA_PACKAGES_IF_GPU=\"CUDA\" # or CuArrays for older Julia versions\nJULIA_NUM_THREADS=4\n#---------------------------------------------------#\n\nif [ -z `which julia` ]; then\n  # Install Julia\n  JULIA_VER=`cut -d '.' -f -2 <<< \"$JULIA_VERSION\"`\n  echo \"Installing Julia $JULIA_VERSION on the current Colab Runtime...\"\n  BASE_URL=\"https://julialang-s3.julialang.org/bin/linux/x64\"\n  URL=\"$BASE_URL/$JULIA_VER/julia-$JULIA_VERSION-linux-x86_64.tar.gz\"\n  wget -nv $URL -O /tmp/julia.tar.gz # -nv means \"not verbose\"\n  tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n  rm /tmp/julia.tar.gz\n\n  # Install Packages\n  nvidia-smi -L &> /dev/null && export GPU=1 || export GPU=0\n  if [ $GPU -eq 1 ]; then\n    JULIA_PACKAGES=\"$JULIA_PACKAGES $JULIA_PACKAGES_IF_GPU\"\n  fi\n  for PKG in `echo $JULIA_PACKAGES`; do\n    echo \"Installing Julia package $PKG...\"\n    julia -e 'using Pkg; pkg\"add '$PKG'; precompile;\"' &> /dev/null\n  done\n\n  # Install kernel and rename it to \"julia\"\n  echo \"Installing IJulia kernel...\"\n  LD_PRELOAD_ julia -e 'using IJulia; IJulia.installkernel(\"julia\", env=Dict(\n      \"JULIA_NUM_THREADS\"=>\"'\"$JULIA_NUM_THREADS\"'\"))'\n  KERNEL_DIR=`julia -e \"using IJulia; print(IJulia.kerneldir())\"`\n  KERNEL_NAME=`ls -d \"$KERNEL_DIR\"/julia*`\n  mv -f $KERNEL_NAME \"$KERNEL_DIR\"/julia  \n\n  echo ''\n  echo \"Successfully installed `julia -v`!\"\n  echo \"Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\"\n  echo \"jump to the 'Checking the Installation' section.\"\nfi\n' returned non-zero exit status 127."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5475b72-0c64-4a46-a37b-9e05ba8f134c",
      "metadata": {
        "id": "e5475b72-0c64-4a46-a37b-9e05ba8f134c"
      },
      "outputs": [],
      "source": [
        "# First, activate the environment and load the necessary packages\n",
        "using BlochSimulators\n",
        "using ComputationalResources\n",
        "using StructArrays"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a83bdc1f-e226-4dc3-b8ab-55e70ae489f2",
      "metadata": {
        "id": "a83bdc1f-e226-4dc3-b8ab-55e70ae489f2"
      },
      "source": [
        "## Simulation setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab769466-629b-4ce4-9dae-8283bc290d7d",
      "metadata": {
        "id": "ab769466-629b-4ce4-9dae-8283bc290d7d"
      },
      "outputs": [],
      "source": [
        "# Now construct a FISP sequence struct (see `src/sequences/fisp.jl`\n",
        "# for which fields are necessary and which constructors exist)\n",
        "\n",
        "nTR = 1000; # nr of TRs used in the simulation\n",
        "RF_train = LinRange(1, 90, nTR) |> collect; # flip angle train\n",
        "TR, TE, TI = 0.010, 0.005, 0.100; # repetition time, echo time, inversion delay\n",
        "max_state = 64; # maximum number of configuration states to keep track of\n",
        "\n",
        "sequence = FISP2D(RF_train, TR, TE, max_state, TI);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f63f113e-dfba-4638-9386-b75f7d493bc4",
      "metadata": {
        "id": "f63f113e-dfba-4638-9386-b75f7d493bc4"
      },
      "outputs": [],
      "source": [
        "# Next, set the desired input tissue properties for which the\n",
        "# FISP sequence response will be simulated\n",
        "T₁_range = logrange(0.1, 5.0, 50); # T₁ range\n",
        "T₂_range = logrange(0.025, 0.5, 50); # T₂ range\n",
        "\n",
        "# Generate valid combinations of T₁ and T₂ and store them in custom T₁T₂ struct\n",
        "parameters = ([T₁T₂(T₁,T₂) for T₁ ∈ T₁_range, T₂ ∈ T₂_range if T₁ > T₂]);\n",
        "\n",
        "println(\"Length parameters: $(length(parameters))\")\n",
        "\n",
        "# Now we can perform the simulations using different hardware resources"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d6f3266-605a-4d22-88ce-de400d476ec7",
      "metadata": {
        "id": "0d6f3266-605a-4d22-88ce-de400d476ec7"
      },
      "source": [
        "## Single-threaded CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3b8dd8b-3849-4cb0-a824-b8bab39c06a9",
      "metadata": {
        "id": "b3b8dd8b-3849-4cb0-a824-b8bab39c06a9"
      },
      "outputs": [],
      "source": [
        "# Note that the first time a function is called in a Julia session,\n",
        "# a precompilation procedure starts and the runtime for subsequent function\n",
        "# calls are significantly faster\n",
        "@time dictionary = simulate_magnetization(CPU1(), sequence, parameters);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dad6f37-080e-49dc-987f-5fadf85c934e",
      "metadata": {
        "id": "8dad6f37-080e-49dc-987f-5fadf85c934e"
      },
      "outputs": [],
      "source": [
        "# The second time a function is called with arguments of similar types,\n",
        "# the pre-compiled version is called immediatly.\n",
        "@time dictionary = simulate_magnetization(CPU1(), sequence, parameters);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd0a41c8-46d3-4d33-9abc-6e4b2f957d4d",
      "metadata": {
        "id": "fd0a41c8-46d3-4d33-9abc-6e4b2f957d4d"
      },
      "outputs": [],
      "source": [
        "# Note that the dictionary is a matrix with the magnetization response (at echo times)\n",
        "# for all combinations of input tissue properties\n",
        "@assert size(dictionary) == (nTR, length(parameters))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9d0575e-42fd-4015-a272-57aff4f7da9c",
      "metadata": {
        "id": "e9d0575e-42fd-4015-a272-57aff4f7da9c"
      },
      "source": [
        "## Multi-threaded CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "935c8e07-c16a-4f3a-891d-d0b3674130c6",
      "metadata": {
        "id": "935c8e07-c16a-4f3a-891d-d0b3674130c6"
      },
      "outputs": [],
      "source": [
        "# To use multiple threads, Julia must be started with the `--threads=auto`\n",
        "# flag (or some integer instead of `auto`). Alternatively, set the\n",
        "# environent variable `JULIA_NUM_THREADS` to the desired number of threads\n",
        "# in your shell before starting Julia.\n",
        "\n",
        "# Check the number of available threads\n",
        "println(\"Current number of threads: $(Threads.nthreads())\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a940a772-ae01-4757-a248-61ad1d454a2a",
      "metadata": {
        "id": "a940a772-ae01-4757-a248-61ad1d454a2a"
      },
      "outputs": [],
      "source": [
        "# We can simulate in a multi-threaded fashion with the following syntax:\n",
        "@time dictionary = simulate_magnetization(CPUThreads(), sequence, parameters);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdfcbe7d-8cd7-4f50-b4d4-a257e0d603d6",
      "metadata": {
        "id": "cdfcbe7d-8cd7-4f50-b4d4-a257e0d603d6"
      },
      "outputs": [],
      "source": [
        "# In fact, BlochSimulators defaults to using CPUThreads() so we can also call\n",
        "@time dictionary = simulate_magnetization(sequence, parameters);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd5dc657-ad95-477f-a87b-1efcc6827e10",
      "metadata": {
        "id": "cd5dc657-ad95-477f-a87b-1efcc6827e10"
      },
      "source": [
        "## Distributed CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0262b61-1752-4635-bf8f-0930b9c7f747",
      "metadata": {
        "id": "e0262b61-1752-4635-bf8f-0930b9c7f747"
      },
      "outputs": [],
      "source": [
        "# For distributed CPU mode, use the Distribute packages (ships with Julia)\n",
        "# to add workers first\n",
        "\n",
        "using Distributed\n",
        "addprocs(4, exeflags=\"--project=.\")\n",
        "\n",
        "# Alternatively, if you can ssh into some other machine,\n",
        "# you can add CPUs from that machine as follows:\n",
        "# addprocs([(\"12.345.67.89\", 4)], exeflags=\"--project=.\")\n",
        "\n",
        "# Or, if you want to run this code on cluster with a queuing system, use ClusterManagers package.\n",
        "#\n",
        "# After workers have been added, load BlochSimulators on all workers\n",
        "# and then start a distributed dictionary generation with:\n",
        "@everywhere using BlochSimulators\n",
        "\n",
        "println(\"Current number of workers: $(nworkers())\")\n",
        "@time dictionary = simulate_magnetization(CPUProcesses(), sequence, parameters);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "186dc3ce-16d7-43df-9075-586183cc35c3",
      "metadata": {
        "id": "186dc3ce-16d7-43df-9075-586183cc35c3"
      },
      "source": [
        "## GPU (CUDA device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5993283-ae45-4ec3-adfa-28ca35ac27e3",
      "metadata": {
        "id": "f5993283-ae45-4ec3-adfa-28ca35ac27e3"
      },
      "outputs": [],
      "source": [
        "# First, let's check if a CUDA device is available\n",
        "println(\"Active CUDA device:\");\n",
        "BlochSimulators.CUDA.device();\n",
        "\n",
        "# To perform simulations on GPU, we first convert the sequence and parameters\n",
        "# to single precision and then send them to the gpu. To this end, BlochSimulators\n",
        "# exports a `f32` function which recursively converts inputs to single precision.\n",
        "# Similarly, a `gpu` function is exported which sends the input to the GPU.\n",
        "\n",
        "cu_sequence = sequence |> f32 |> gpu;\n",
        "cu_parameters = parameters |> f32 |> gpu;\n",
        "\n",
        "# Remember, the first time a compilation procedure takes place which, especially\n",
        "# on GPU, can take some time.\n",
        "CUDA.@time dictionary = simulate_magnetization(CUDALibs(), cu_sequence, cu_parameters);\n",
        "\n",
        "# Call the pre-compiled version, it should be a lot faster\n",
        "CUDA.@time dictionary = simulate_magnetization(CUDALibs(), cu_sequence, cu_parameters);\n",
        "\n",
        "# Now let's increase the number of tissue property combinations for which\n",
        "# simulations are performed:\n",
        "T₁ = rand(500_000)\n",
        "T₂ = 0.1 * T₁\n",
        "cu_parameters = (@parameters T₁ T₂) |> f32 |> gpu\n",
        "\n",
        "CUDA.@time dictionary = simulate_magnetization(CUDALibs(), cu_sequence, cu_parameters);"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Julia 1.11.1",
      "language": "julia",
      "name": "julia-1.11"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.11.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}